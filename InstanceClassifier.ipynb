{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InstanceClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahgin/DeepLeaningProj/blob/master/InstanceClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvEbIcsEMonV",
        "colab_type": "code",
        "outputId": "57a90df6-caf5-42b8-d765-1e1e749c3695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# mount data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWLhQPqkJB7L",
        "colab_type": "text"
      },
      "source": [
        "## Copy data from google drive to colab env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wggjXXwF6Ri8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir /Drive\n",
        "!ls /Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8UMCBW2HrS3",
        "colab_type": "code",
        "outputId": "64161881-a649-497b-bae4-33c51cf945c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "#!mkdir /Drive\n",
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "for src in glob.glob('/content/gdrive/My Drive/videos_2/yt_bb_detection_train/*.zip'):\n",
        "  dst = f'/Drive/{os.path.basename(src)}'\n",
        "  print(src, dst)    \n",
        "  if os.path.exists(src) and not os.path.exists(dst):\n",
        "    print(f'copy {src} to {dst}')\n",
        "    shutil.copy2(src, dst)\n",
        "  \n",
        " # Create a ZipFile Object and load sample.zip in it\n",
        "for z in glob.glob('/Drive/*zip'):\n",
        "  with ZipFile(z, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall('/Drive')\n",
        "    \n",
        "!ls /Drive\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/0.zip /Drive/0.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/0.zip to /Drive/0.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/1.zip /Drive/1.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/1.zip to /Drive/1.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/2.zip /Drive/2.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/2.zip to /Drive/2.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/3.zip /Drive/3.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/3.zip to /Drive/3.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/4.zip /Drive/4.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/4.zip to /Drive/4.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/5.zip /Drive/5.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/5.zip to /Drive/5.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/6.zip /Drive/6.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/6.zip to /Drive/6.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/7.zip /Drive/7.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/7.zip to /Drive/7.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/8.zip /Drive/8.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/8.zip to /Drive/8.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/9.zip /Drive/9.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/9.zip to /Drive/9.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/10.zip /Drive/10.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/10.zip to /Drive/10.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/11.zip /Drive/11.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/11.zip to /Drive/11.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/12.zip /Drive/12.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/12.zip to /Drive/12.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/13.zip /Drive/13.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/13.zip to /Drive/13.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/14.zip /Drive/14.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/14.zip to /Drive/14.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/15.zip /Drive/15.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/15.zip to /Drive/15.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/16.zip /Drive/16.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/16.zip to /Drive/16.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/17.zip /Drive/17.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/17.zip to /Drive/17.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/18.zip /Drive/18.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/18.zip to /Drive/18.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/19.zip /Drive/19.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/19.zip to /Drive/19.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/20.zip /Drive/20.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/20.zip to /Drive/20.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/21.zip /Drive/21.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/21.zip to /Drive/21.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/23.zip /Drive/23.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/23.zip to /Drive/23.zip\n",
            "/content/gdrive/My Drive/videos_2/yt_bb_detection_train/yt_bb_detection_train.zip /Drive/yt_bb_detection_train.zip\n",
            "copy /content/gdrive/My Drive/videos_2/yt_bb_detection_train/yt_bb_detection_train.zip to /Drive/yt_bb_detection_train.zip\n",
            "0\t12\t15.zip\t19\t21.zip\t4.zip  8\n",
            "0.zip\t12.zip\t16\t19.zip\t23\t5      8.zip\n",
            "1\t13\t16.zip\t1.zip\t23.zip\t5.zip  9\n",
            "10\t13.zip\t17\t2\t2.zip\t6      9.zip\n",
            "10.zip\t14\t17.zip\t20\t3\t6.zip  yt_bb_detection_train.zip\n",
            "11\t14.zip\t18\t20.zip\t3.zip\t7\n",
            "11.zip\t15\t18.zip\t21\t4\t7.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XSA4C12JeqS",
        "colab_type": "text"
      },
      "source": [
        "## Data partition to train/test folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umgn7pe_cK8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "def list_dirs(directory):\n",
        "    \"\"\"Returns all directories in a given directory\n",
        "    \"\"\"\n",
        "    return [f for f in pathlib.Path(directory).iterdir() if f.is_dir()]\n",
        "\n",
        "def list_files(directory):\n",
        "    \"\"\"Returns all files in a given directory\n",
        "    \"\"\"\n",
        "    return [\n",
        "        f\n",
        "        for f in pathlib.Path(directory).iterdir()\n",
        "        if f.is_file() and not f.name.startswith(\".\")\n",
        "    ]\n",
        "\n",
        "def setup_files(class_dir, seed):\n",
        "    \"\"\"Returns shuffled files\n",
        "    \"\"\"\n",
        "    # make sure its reproducible\n",
        "    random.seed(seed)\n",
        "\n",
        "    files = list_files(class_dir)\n",
        "\n",
        "    files.sort()\n",
        "    random.shuffle(files)\n",
        "    return files\n",
        "\n",
        "def ratio(input, output=\"output\", seed=1337, ratio=(0.8, 0.1, 0.1)):\n",
        "    # make up for some impression\n",
        "    assert round(sum(ratio), 5) == 1\n",
        "    assert len(ratio) in (2, 3)\n",
        "\n",
        "    for class_dir in list_dirs(input):\n",
        "        for instance_dir in list_dirs(class_dir):\n",
        "            instancename = os.path.basename(instance_dir)\n",
        "            classname = os.path.basename(class_dir)\n",
        "            fulloutput = os.path.join(classname,instancename)\n",
        "            #output_dir = os.path.join(output, classname ,instancename)\n",
        "            split_class_dir_ratio(instance_dir, output, fulloutput, ratio, seed, None)\n",
        "\n",
        "\n",
        "def split_class_dir_fixed(class_dir, output, fixed, seed, prog_bar):\n",
        "    \"\"\"Splits one very class folder\n",
        "    \"\"\"\n",
        "    files = setup_files(class_dir, seed)\n",
        "\n",
        "    if not len(files) > sum(fixed):\n",
        "        raise ValueError(\n",
        "            f'The number of samples in class \"{class_dir.stem}\" are too few. There are only {len(files)} samples available but your fixed parameter {fixed} requires at least {sum(fixed)} files. You may want to split your classes by ratio.'\n",
        "        )\n",
        "\n",
        "    split_train = len(files) - sum(fixed)\n",
        "    split_val = split_train + fixed[0]\n",
        "\n",
        "    li = split_files(files, split_train, split_val, len(fixed) == 2)\n",
        "    copy_files(li, class_dir, output, prog_bar)\n",
        "    return len(files)\n",
        "\n",
        "def split_class_dir_ratio(class_dir, output, fulloutput, ratio, seed, prog_bar):\n",
        "    \"\"\"Splits one very class folder\n",
        "    \"\"\"\n",
        "    files = setup_files(class_dir, seed)\n",
        "\n",
        "    split_train = int(ratio[0] * len(files))\n",
        "    split_val = split_train + int(ratio[1] * len(files))\n",
        "\n",
        "    li = split_files(files, split_train, split_val, len(ratio) == 3)\n",
        "    copy_files(li, class_dir, output, fulloutput, prog_bar)\n",
        "\n",
        "\n",
        "def split_files(files, split_train, split_val, use_test):\n",
        "    \"\"\"Splits the files along the provided indices\n",
        "    \"\"\"\n",
        "    files_train = files[:split_train]\n",
        "    files_val = files[split_train:split_val] if use_test else files[split_train:]\n",
        "\n",
        "    li = [(files_train, \"train\"), (files_val, \"test\")]\n",
        "\n",
        "    # optional test folder\n",
        "    if use_test:\n",
        "        files_test = files[split_val:]\n",
        "        li.append((files_test, \"test\"))\n",
        "    return li\n",
        "\n",
        "\n",
        "def copy_files(files_type, class_dir, output, fulloutput, prog_bar):\n",
        "    \"\"\"Copies the files from the input folder to the output folder\n",
        "    \"\"\"\n",
        "    # get the last part within the file\n",
        "    for (files, folder_type) in files_type:\n",
        "        full_path = os.path.join(output, folder_type, fulloutput)\n",
        "\n",
        "        pathlib.Path(full_path).mkdir(parents=True, exist_ok=True)\n",
        "        for f in files:\n",
        "            if not prog_bar is None:\n",
        "                prog_bar.update()\n",
        "            shutil.copy2(f, full_path)\n",
        "            \n",
        "            \n",
        "ratio('/Drive', output='/Drive/data/', seed=1337, ratio=(.8, .2))  #the partition to 80% train 20% test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqURTd-KjOb",
        "colab_type": "text"
      },
      "source": [
        "## Augmentation Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFFxW22vKh-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubPolicy(object):\n",
        "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
        "        ranges = {\n",
        "            \"shearX\": np.linspace(0, 0.3, 10),\n",
        "            \"shearY\": np.linspace(0, 0.3, 10),\n",
        "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
        "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
        "            \"rotate\": np.linspace(0, 30, 10),\n",
        "            \"color\": np.linspace(0.0, 0.9, 10),\n",
        "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
        "            \"solarize\": np.linspace(256, 0, 10),\n",
        "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
        "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"autocontrast\": [0] * 10,\n",
        "            \"equalize\": [0] * 10,\n",
        "            \"invert\": [0] * 10\n",
        "        }\n",
        "\n",
        "        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
        "        def rotate_with_fill(img, magnitude):\n",
        "            rot = img.convert(\"RGBA\").rotate(magnitude)\n",
        "            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n",
        "\n",
        "        func = {\n",
        "            \"shearX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"shearY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"translateX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
        "                fillcolor=fillcolor),\n",
        "            \"translateY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n",
        "                fillcolor=fillcolor),\n",
        "            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n",
        "            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n",
        "            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n",
        "            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n",
        "            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n",
        "            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n",
        "            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n",
        "            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n",
        "        }\n",
        "\n",
        "        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n",
        "        #     operation1, ranges[operation1][magnitude_idx1],\n",
        "        #     operation2, ranges[operation2][magnitude_idx2])\n",
        "        self.p1 = p1\n",
        "        self.operation1 = func[operation1]\n",
        "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
        "        self.p2 = p2\n",
        "        self.operation2 = func[operation2]\n",
        "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n",
        "        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n",
        "        return img\n",
        "\n",
        "\n",
        "class ImageNetPolicy(object):\n",
        "    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n",
        "        Example:\n",
        "        >>> policy = ImageNetPolicy()\n",
        "        >>> transformed = policy(image)\n",
        "        Example as a PyTorch Transform:\n",
        "        >>> transform=transforms.Compose([\n",
        "        >>>     transforms.Resize(256),\n",
        "        >>>     ImageNetPolicy(),\n",
        "        >>>     transforms.ToTensor()])\n",
        "    \"\"\"\n",
        "    def __init__(self, fillcolor=(128, 128, 128)):\n",
        "        self.policies = [\n",
        "            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n",
        "            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n",
        "            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n",
        "            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n",
        "            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n",
        "            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n",
        "            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
        "        return self.policies[policy_idx](img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"AutoAugment ImageNet Policy\"\n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkf77MeWKujR",
        "colab_type": "text"
      },
      "source": [
        "## Create DataSet Class - Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T87rRVL6N5Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataSet object\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import imageio\n",
        "import numpy as np  \n",
        "from PIL import Image\n",
        "\n",
        "class ClassDataset(Dataset):\n",
        "      \n",
        "  def __init__(self, basedir, transform, percentage):\n",
        "        super().__init__()\n",
        "        files = glob.glob(os.path.join(basedir ,'**/*.jpg'), recursive=True)\n",
        "        if(percentage < 100):\n",
        "          files_num = len(list(files))\n",
        "          choosefilesnumber = int(files_num * percentage / 100)\n",
        "          print(f'choosefilesnumber: {choosefilesnumber}  filesnum: {files_num}')\n",
        "          print((list(files)))\n",
        "          selectedfiles = np.random.choice(files, choosefilesnumber, replace=False)\n",
        "        elif(percentage == 100):\n",
        "          selectedfiles = files\n",
        "        \n",
        "        self.data = pd.DataFrame([self._split_file(f) for f in selectedfiles], \n",
        "                            columns=['class_id', 'file_path'])\n",
        "        names  = np.unique(self.data['class_id'])\n",
        "        \n",
        "        self.classDict = {str:index for index, str in enumerate(names)}          \n",
        "        self.data['class_num'] = self.data['class_id'].map(self.classDict)\n",
        "        self.transform = transform\n",
        "        \n",
        "  def _split_file(self, f):\n",
        "        parts = f.split(os.sep)[-3:-1]\n",
        "        return parts[0], f   #label is originaly a str\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      dat = self.data.iloc[index]\n",
        "      img = Image.open(dat['file_path'])\n",
        "      if self.transform:\n",
        "          img = self.transform(img)\n",
        "      img = np.resize(img, (3,128,128))\n",
        "      img = np.asarray(img)\n",
        "      return (img.astype(np.float32), dat['class_num'])\n",
        "     \n",
        "  def __len__(self):\n",
        "      return len(self.data)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHgzS0BSK3r2",
        "colab_type": "text"
      },
      "source": [
        "## Create DataSet Class - Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiQtzYuUM88R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataSet object\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import imageio\n",
        "import numpy as np  \n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class InstanceDataset(Dataset):\n",
        "    def __init__(self, basedir, transform, percentage):\n",
        "        super().__init__()\n",
        "        files = glob.glob(os.path.join(basedir ,'**/*.jpg'), recursive=True)\n",
        "        if(percentage < 100):\n",
        "          files_num = len(list(files))\n",
        "          choosefilesnumber = int(files_num * percentage / 100)\n",
        "          print(f'choosefilesnumber: {choosefilesnumber}  filesnum: {files_num}')\n",
        "          print((list(files)))\n",
        "          selectedfiles = np.random.choice(files, choosefilesnumber, replace=False)\n",
        "        elif(percentage == 100):\n",
        "          selectedfiles = files\n",
        "        \n",
        "        self.data = pd.DataFrame([self._split_file(f) for f in selectedfiles], \n",
        "                            columns=['instance_id', 'file_path'])\n",
        "        names  = np.unique(self.data['instance_id'])\n",
        "        \n",
        "        self.instanceDict = {str:index for index, str in enumerate(names)}          \n",
        "        self.data['instance_num'] = self.data['instance_id'].map(self.instanceDict)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def _split_file(self, f):\n",
        "        parts = f.split(os.sep)[-3:-1]\n",
        "        return parts[1], f   #label is originaly a str\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      dat = self.data.iloc[index]\n",
        "      #img = imageio.imread(dat['file_path'])\n",
        "      img = Image.open(dat['file_path'])\n",
        "      if self.transform:\n",
        "          img = self.transform(img)\n",
        "      img = np.resize(img, (3,128,128))\n",
        "      img = np.asarray(img)\n",
        "      return (img.astype(np.float32), dat['instance_num'])\n",
        "     \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3_nmptELe4_",
        "colab_type": "text"
      },
      "source": [
        "## Create train and test datasets including augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgdhhhjcwc1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "\n",
        "#basedir = '/content/gdrive/My Drive/video_data/'       \n",
        "trainbasedir = '/Drive/data/train'   \n",
        "testbasedir = '/Drive/data/test'\n",
        "\n",
        "data_transforms = transforms.Compose([transforms.Resize((256,256)),transforms.RandomResizedCrop(224), \n",
        "                         transforms.RandomHorizontalFlip(), #ImageNetPolicy(), \n",
        "                         transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "#train_set = ClassDataset(trainbasedir, data_transforms, 50)\n",
        "#test_set = ClassDataset(testbasedir, None, 100)\n",
        "train_set = InstanceDataset(trainbasedir, data_transforms, 100) \n",
        "test_set = InstanceDataset(testbasedir, None, 100)                                                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYXJwgEIW4nc",
        "colab_type": "code",
        "outputId": "f1952e85-d730-40d0-bdcb-90c515b9e9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(len((train_set.data['class_num'])))\n",
        "print(len(np.unique(train_set.data['class_num'])))\n",
        "print(max(train_set.data['class_num']))\n",
        "print(len((test_set.data['class_num'])))\n",
        "print(len(np.unique(test_set.data['class_num'])))\n",
        "print(max(test_set.data['class_num']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40331\n",
            "23\n",
            "22\n",
            "18350\n",
            "23\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1nkVWqUqjEy",
        "colab_type": "code",
        "outputId": "0c657222-e234-41fd-c6af-bb0664f9e471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(len((train_set.data['instance_num'])))\n",
        "print(len(np.unique(train_set.data['instance_num'])))\n",
        "print(max(train_set.data['instance_num']))\n",
        "print(len((test_set.data['instance_num'])))\n",
        "print(len(np.unique(test_set.data['instance_num'])))\n",
        "print(max(test_set.data['instance_num']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80662\n",
            "6476\n",
            "6475\n",
            "18350\n",
            "6287\n",
            "6286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMwnJ5adL8RK",
        "colab_type": "text"
      },
      "source": [
        "## Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZBZOwY1Ra4",
        "colab_type": "code",
        "outputId": "b5660d22-79ab-404d-d4eb-75c6ff0ca4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True,\n",
        "                 num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=test_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=False,\n",
        "                 num_workers=4)\n",
        "\n",
        "print('Train size: {}'.format(len(train_loader)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 1614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGwIM6Y2MCXO",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg0UH6MdAen0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perf_measure(y_actual, y_pred):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    cm = np.zeros((2,2))\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_actual[i]==y_pred[i]:\n",
        "           TP += 1\n",
        "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_pred[i]:\n",
        "           TN += 1\n",
        "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
        "           FN += 1\n",
        "\n",
        "        cm[0][0] = TP\n",
        "        cm[0][1] = FP\n",
        "        cm[1][0]  = FN\n",
        "        cm[1][1]  = TN\n",
        "\n",
        "    return (cm)\n",
        "  \n",
        "def create_confusion_matrix_fig(c_cm):\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    plt.imshow(c_cm, interpolation='nearest')\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.colorbar()\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Men7NTFOMMAn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B45pmKnJqWZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "\n",
        "import time \n",
        "import tqdm\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "assert use_cuda\n",
        "\n",
        "model = models.resnet18(pretrained=False) #for third net to load our trained instance net\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter('with_cm')    \n",
        "    \n",
        "num_final_in = model.fc.in_features\n",
        "\n",
        "NUM_CLASSES_Instance = 6476  #len(np.unique(dataset.data['instance_num']))\n",
        "NUM_CLASSES_Class = 23\n",
        "\n",
        "model.fc = nn.Linear(num_final_in, NUM_CLASSES_Instance)      \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003) #, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if use_cuda:\n",
        "  model = model.cuda()\n",
        "  model.to(torch.device(\"cuda\"))\n",
        "\n",
        "#model = torch.load('/content/gdrive/My Drive/myModels/InstanceModel.pth')\n",
        "#num_final_in = model.fc.in_features\n",
        "#print(f'last fc number: {num_final_in})\n",
        "#model.fc = nn.Linear(num_final_in, NUM_CLASSES_Instance) \n",
        "\n",
        "for epoch in range(50):\n",
        "    # trainning\n",
        "    sum_loss = 0 \n",
        "    total_cnt = 0\n",
        "    correct_cnt = 0\n",
        "    tf = time.time()\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "    #for batch_idx, (x, target) in enumerate(tqdm.tqdm(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "        \n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                \n",
        "        pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += x.data.size()[0]\n",
        "        correct_cnt += (pred_label[1] == target.data).sum()\n",
        "        sum_loss += loss.data\n",
        "        \n",
        "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
        "            print ('==>>> epoch: {}, batch index: {}, train loss: {:.6f}, acc: {}'.format(\n",
        "                epoch, batch_idx+1, sum_loss/batch_idx, float(correct_cnt)/total_cnt))    \n",
        "            \n",
        "    cm = perf_measure(target.data, pred_label[1])\n",
        "    cur_fig = create_confusion_matrix_fig(cm)\n",
        "    writer.add_figure('train_confusion_matrix', cur_fig, global_step=None, close=True, walltime=None)\n",
        "    writer.add_scalar('train accuracy', float(correct_cnt)/total_cnt, epoch)\n",
        "    writer.add_scalar('train loss', sum_loss/len(train_loader), epoch)\n",
        "    \n",
        "     # testing    \n",
        "    correct_cnt, sum_loss = 0, 0\n",
        "    total_cnt = 0\n",
        "    for batch_idx, (x, target) in enumerate(test_loader):\n",
        "        x = x.float()\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "        out = model(x)   \n",
        "        loss = criterion(out, target)\n",
        "        \n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += x.data.size()[0]\n",
        "        correct_cnt += (pred_label == target.data).sum()\n",
        "        # smooth averages\n",
        "        sum_loss += loss.data\n",
        "        \n",
        "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
        "            print ('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
        "                epoch, batch_idx+1, sum_loss/batch_idx,float(correct_cnt)/total_cnt))\n",
        "    \n",
        "    try:\n",
        "      cm = perf_measure(target.data, pred_label)\n",
        "      cur_fig = create_confusion_matrix_fig(cm)\n",
        "      writer.add_figure('test_confusion_matrix', cur_fig, global_step=None, close=True, walltime=None)\n",
        "    except:\n",
        "      print(\"An exception in test_confusion_matrix\")\n",
        "      continue\n",
        "    writer.add_scalar('test accuracy', float(correct_cnt)/total_cnt, epoch)\n",
        "    writer.add_scalar('test loss', sum_loss/len(test_loader), epoch)\n",
        "\n",
        "#torch.save(model.state_dict(), 'yt_bb_detection_train/mymodel3')\n",
        "writer.close()\n",
        "\n",
        "elapsed = time.time() - tf\n",
        "print(f'Elapsed time: {elapsed}')\n",
        "\n",
        "torch.save(model, '/content/gdrive/My Drive/myModels/newInstanceModel.pth')\n",
        "\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.load_state_dict(torch.load(PATH))\n",
        "# model.eval()\n",
        "\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}